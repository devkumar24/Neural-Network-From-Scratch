{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from visualization.decision_boundary import plot_decision_boundary\n",
    "from activation.activation_functions import softmax\n",
    "from perceptron.MLP import ANN\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X,y = make_circles(n_samples=500,noise = 0.2,factor=0.2,shuffle=True,random_state=2)\n",
    "\n",
    "SPLIT_SIZE = 0.9\n",
    "SPLIT_NO = int(X.shape[0]*SPLIT_SIZE)\n",
    "\n",
    "x_train = X[:SPLIT_NO]\n",
    "y_train = y[:SPLIT_NO]\n",
    "x_test = X[SPLIT_NO:]\n",
    "y_test = y[SPLIT_NO:]\n",
    "\n",
    "x_train.shape\n",
    "y_test.shape\n",
    "\n",
    "# create model\n",
    "model = ANN(hidden_layers=[32,32,16,8],output_layer=2,input_layer=2)\n",
    "\n",
    "# fit the model\n",
    "hist = model.fit(x_train,y_train,batch_size=32,epochs=25,metrics = \"accuracy\")\n",
    "\n",
    "# prediction of model\n",
    "# pred is a dictionary which contains output and probability of resulted output\n",
    "pred = model.predict(x_test[23])\n",
    "\n",
    "y_test[23]\n",
    "\n",
    "pred[\"output\"]\n",
    "\n",
    "# calculate accuracy of training set\n",
    "model.cal_accuracy(x_train,y_train,\"accuracy\")\n",
    "\n",
    "# calculate accuracy of testing set\n",
    "model.cal_accuracy(x_test,y_test,\"accuracy\")\n",
    "\n",
    "hist[1]\n",
    "\n",
    "# plot decision boundary\n",
    "plot_decision_boundary(lambda x : model.predict(x)[\"output\"],X,y)\n",
    "\n",
    "# indexes denote weight metrics e.g., 0--->w[1] and so on, as there are total 5 layers \n",
    "# 4 hidden and one output so there are 5 weight metrics\n",
    "model.model_layers\n",
    "\n",
    "hist\n",
    "\n",
    "pred\n",
    "\n",
    "plt.plot(hist[\"loss_per_epoch\"])\n",
    "\n",
    "#############CONCLUSION###############\n",
    "# as this is very bad loss graph, to we can say that our model is overfitting, there is trend in loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
