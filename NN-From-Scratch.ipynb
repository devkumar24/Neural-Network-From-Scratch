{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code-NN\n",
    " - It is way similar to tensorflow model but not as tensorflow, tensorflow is more advance than \n",
    "    this, but I am improving this a lot that It should compete tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F:\\Anaconda_Files\\Anaconda\\envs\\tensorflow-env\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import make_blobs,make_circles,make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [0,1],\n",
    "    [1,1]\n",
    "])\n",
    "y = np.array([0,1,1,0])\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1],c = y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(Z):\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    \"\"\"\n",
    "    softmax = e^y(i)/sum(e^y(i))\n",
    "    \"\"\"\n",
    "    \n",
    "    ea = np.exp(y)\n",
    "    \n",
    "    total = ea/np.sum(ea,axis = 1,keepdims=True)\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \n",
    "    def __init__(self,hidden_layers,output_layer,input_layer,activation = \"relu\",output_layer_activation = \"softmax\"):\n",
    "        # Dictionary of all layers with its weight and bias\n",
    "        model_layers = {}\n",
    "        # make self varible for activation\n",
    "        self.activation = activation\n",
    "        # Total no of layers include input + hidden + output layers \n",
    "        total_layers = 1 + len(hidden_layers) + 1\n",
    "        # layers list [input_layer,hidden_layer,output_layer]\n",
    "        # layers[0]--->input_layer\n",
    "        #layers[total_layer-1]--->output_layer\n",
    "        layers = []\n",
    "        layers.append(input_layer)\n",
    "        for i in hidden_layers:\n",
    "            layers.append(i)\n",
    "        layers.append(output_layer)\n",
    "        layers = np.array(layers)\n",
    "        for layer_no in range(total_layers-1):\n",
    "            model_layers[layer_no] = [np.random.randn(layers[layer_no],layers[layer_no+1]),np.zeros((1,layers[layer_no+1]))]\n",
    "        # make class variable self.model_layers to store model_layers\n",
    "        self.model_layers = model_layers\n",
    "        \n",
    "    # function to do forward pass\n",
    "    def forward_propagation(self,X):\n",
    "        '''\n",
    "        This function forward_propagation will make model variable that is having \n",
    "        self.model_layers which includes weight and bias for particular layer,\n",
    "        then it will 4 list i.e., activation units,weight matrix,bias matrix and \n",
    "        Z matrix, and it will return last activation unit.\n",
    "        \n",
    "        \n",
    "        Take an input X(array) and do forward pass operation and return last activation\n",
    "        function.\n",
    "        \n",
    "        example ->\n",
    "        Input: X(array)\n",
    "        Operation: hidden_layers = [4,3]\n",
    "                   input_layer = 2\n",
    "                   output_layer = 2\n",
    "                   \n",
    "                   total_layers = 4\n",
    "                   layers = [2,4,3,2]\n",
    "                   \n",
    "                   Z[0] = X*W[0] + b[0]\n",
    "                   A[0] = activation_function(Z[0])\n",
    "                   \n",
    "                   Z[1] = A[1]*W[1] + b[1]\n",
    "                   A[1] = activation_function(Z[1])\n",
    "        \n",
    "                   Z[2] = A[1]*W[2] + b[2]\n",
    "                   A[2] = activation_function(Z[2])\n",
    "                   \n",
    "        Output: A[2]\n",
    "        '''\n",
    "        # make model variable of self.model_layers\n",
    "        model  = self.model_layers\n",
    "        # make 4 lists of weight metrics, bias metrics, activation metrics, Z metrics\n",
    "        W = []\n",
    "        b = []\n",
    "        Z = []\n",
    "        A = []\n",
    "        # append values in Weight metrics and bias metrics\n",
    "        for key in model.keys():\n",
    "            W.append(model[key][0])\n",
    "            b.append(model[key][1])\n",
    "        W = np.array(W)\n",
    "        # append values in activation units metrics and Z mertics \n",
    "        for i in range(W.shape[0]):\n",
    "            if i == 0:\n",
    "                Z.append(np.dot(X,W[0]) + b[0])\n",
    "                A.append(np.tanh(Z[0]))\n",
    "                \n",
    "            else :\n",
    "                if i == W.shape[0] - 1:\n",
    "                    Z.append(np.dot(A[i-1],W[i]) + b[i])\n",
    "                    A.append(softmax(Z[i]))\n",
    "                else:\n",
    "                    Z.append(np.dot(A[i-1],W[i]) + b[i])\n",
    "                    A.append(np.tanh(Z[i]))\n",
    "                    \n",
    "        # make class variables of all four lists\n",
    "        self.activation_units = (A)\n",
    "        self.W = (W)\n",
    "        self.b = (b)\n",
    "        self.Z = (Z)\n",
    "        \n",
    "        return A[-1]\n",
    "    \n",
    "    # function to do backpropagation in Multi Layer Perceptron\n",
    "    def backward_propagation(self,X,y,learning_rate = 0.01):\n",
    "        '''\n",
    "        This function backward_propagation is initally taking self.model_layers,\n",
    "        self.W,self.b,self.activation_units these 4 will help to do backpropagation \n",
    "        in Multi Layer Perceptron.\n",
    "        \n",
    "        As above 4 things will help in computing dZ,dW,db i.e., the derivatives of Z metrics,\n",
    "        Weight metrics and bias metrics and later perform gradient descent algo. and\n",
    "        update weight and biases\n",
    "        \n",
    "        It takes an input as X(input array) and its prediction array(y), and takes an\n",
    "        input hyper-parameter learning_rate to perform gradient descent algo.\n",
    "        \n",
    "        Therefore, \n",
    "            Backpropagation is basiaclly perform gardient descent algo, and is to\n",
    "            compute dZ,dW,db \n",
    "        example ->\n",
    "        Input: X(input array)\n",
    "        Operation: To Compute dZ,dW,db\n",
    "                   we need W,b,Z,A\n",
    "                   \n",
    "                   dZ[2] = A[2] - y\n",
    "                   dW[2] = (A[1].dZ[2])\n",
    "                   db[2] = dZ[2]\n",
    "                   \n",
    "                   dZ[1] = derivative of activation_function * (dZ[2]*W[2])\n",
    "                   dW[1] = (A[0].dZ[1])\n",
    "                   db[1] = dZ[1]\n",
    "                   \n",
    "                   dZ[0] = derivative of activation_function * (dZ[1]*W[1])\n",
    "                   dW[0] = (X.dZ[0])\n",
    "                   db[0] = dZ[0]\n",
    "                   \n",
    "        Output: Perfrom Gradient Descent Algo\n",
    "                W[i] -= learning_rate * dW[i]\n",
    "                b[i] -= learning_rate * db[i]\n",
    "        '''\n",
    "        # make model variable of self.model_layers\n",
    "        model  = self.model_layers\n",
    "        W = self.W\n",
    "        b = self.b\n",
    "        A = self.activation_units\n",
    "        dZ = []\n",
    "        db = []\n",
    "        dW = []\n",
    "        # calculate dZ\n",
    "        for i in reversed(range(W.shape[0])):\n",
    "            if i == W.shape[0] - 1:\n",
    "                dZ.append(A[i] - y)    \n",
    "            else:\n",
    "                if i == 0:\n",
    "                    dZ.append( (1-np.square(A[i])) * np.dot(dZ[W.shape[0]-i-2],W[i+1].T) )\n",
    "                else:\n",
    "                    dZ.append( (1-np.square(A[i])) * np.dot(dZ[W.shape[0]-i-2],W[i+1].T) )\n",
    "        # reverse dZ so that dZ will get be related to dW and db\n",
    "        dZ = dZ[::-1]\n",
    "        # calculate dW and db\n",
    "        for i in range(W.shape[0]):\n",
    "            if i == W.shape[0] - 1:\n",
    "                dW.append(np.dot(A[i-1].T,dZ[i]))\n",
    "                db.append(np.sum(dZ[i],axis = 0))    \n",
    "            else:\n",
    "                if i == 0:\n",
    "                    dW.append(np.dot(X.T,dZ[i]))\n",
    "                    db.append(np.sum(dZ[i],axis = 0))\n",
    "                else:\n",
    "                    dW.append(np.dot(A[i-1].T,dZ[i]))\n",
    "                    db.append(np.sum(dZ[i],axis = 0))\n",
    "            \n",
    "            # perform gradient descent algo.\n",
    "            W[i] -= learning_rate * dW[i]\n",
    "            b[i] -= learning_rate * db[i]\n",
    "        # class variable to store W and b, after updation\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "    # Predict function to perform prediction\n",
    "    def predict(self,X):\n",
    "        '''\n",
    "        This function will takes an x_query as input and return the output as per\n",
    "        given y(prediction)\n",
    "        \n",
    "        Return:\n",
    "            1: Probabilities \n",
    "            2: index of max probability\n",
    "        '''\n",
    "        y_out = self.forward_propagation(X)\n",
    "        \n",
    "        return y_out,np.argmax(y_out,axis = 1)\n",
    "    \n",
    "    # Loss Function to calculate loss\n",
    "    def loss(self,y_opt,p):\n",
    "        '''\n",
    "        It will calculate mean squared loss, i.e., categorical cross_entropy loss\n",
    "        \n",
    "        retuurn loss\n",
    "        '''\n",
    "        l = np.mean(y_opt*np.log(p))\n",
    "        return -l\n",
    "    \n",
    "    # Training Function\n",
    "    def train(self,X,y,batch_size,epochs,metrics):\n",
    "        '''\n",
    "        This Train function is basically doing training and perform particular metrics like \n",
    "        \"accurcay\",\"r2Score\", depend on what we calculate, \n",
    "        and it will predict loss after every loss,\n",
    "        it contains a list of training loss, that contains all the losses(the loss calculated after\n",
    "        every iteration,\n",
    "        example->\n",
    "         X.shape[0] = 500\n",
    "         BATCH_SIZE = 32\n",
    "         NO_OF_ITERATIONS = int(X.shape[0]/BATCH_SIZE)-1\n",
    "         training_loss.shape = (len(NO_OF_ITERATIONS))\n",
    "         ).\n",
    "         \n",
    "        Prediction score will be calcuated after each epoch, and it is also having a numpy.ndarray\n",
    "        that store all the prediction score, for each iteration, and shape is same as training_loss\n",
    "        $ y should be one hot vector\n",
    "        $ training_loss is numpy.ndarray\n",
    "        $ epochs is hyper parameter\n",
    "        $ metrics is hyper parameter\n",
    "        '''\n",
    "        training_loss = []\n",
    "        y_opt = to_categorical(y)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"EPOCH-->{}\".format(i+1))\n",
    "            for j in range(int(X.shape[0]/batch_size) - 1):\n",
    "                Y_ = self.forward_propagation(X[j*batch_size:(j+1)*batch_size])\n",
    "                l = self.loss(y_opt[j*batch_size:(j+1)*batch_size],Y_)\n",
    "                self.backward_propagation(X[j*batch_size:(j+1)*batch_size],y_opt[j*batch_size:(j+1)*batch_size])\n",
    "                training_loss.append(l)\n",
    "            print(\" Training Loss----->  \",l)\n",
    "            \n",
    "        y_pred = []\n",
    "        if metrics == \"accuracy\":\n",
    "            for i in range(X.shape[0]):\n",
    "                output,index = self.predict(X[i])\n",
    "                y_pred.append(index)\n",
    "            acc = np.sum(y_pred == y)/y.shape[0]\n",
    "        return training_loss,acc*100\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(hidden_layers=[4,3],output_layer=2,input_layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-->1\n",
      " Training Loss----->   0.23499497921370516\n",
      "EPOCH-->2\n",
      " Training Loss----->   0.22313222519797712\n",
      "EPOCH-->3\n",
      " Training Loss----->   0.21261469219969253\n",
      "EPOCH-->4\n",
      " Training Loss----->   0.20330271698735047\n",
      "EPOCH-->5\n",
      " Training Loss----->   0.19505187976989075\n",
      "EPOCH-->6\n",
      " Training Loss----->   0.18772306052703222\n",
      "EPOCH-->7\n",
      " Training Loss----->   0.18118837723582426\n",
      "EPOCH-->8\n",
      " Training Loss----->   0.1753339864285565\n",
      "EPOCH-->9\n",
      " Training Loss----->   0.17006076614420074\n",
      "EPOCH-->10\n",
      " Training Loss----->   0.16528372231194416\n",
      "EPOCH-->11\n",
      " Training Loss----->   0.16093072503941985\n",
      "EPOCH-->12\n",
      " Training Loss----->   0.15694097153693493\n",
      "EPOCH-->13\n",
      " Training Loss----->   0.1532634136323151\n",
      "EPOCH-->14\n",
      " Training Loss----->   0.1498552792167583\n",
      "EPOCH-->15\n",
      " Training Loss----->   0.14668074802070552\n",
      "EPOCH-->16\n",
      " Training Loss----->   0.1437098011791364\n",
      "EPOCH-->17\n",
      " Training Loss----->   0.1409172414626825\n",
      "EPOCH-->18\n",
      " Training Loss----->   0.13828186984080706\n",
      "EPOCH-->19\n",
      " Training Loss----->   0.1357857995270922\n",
      "EPOCH-->20\n",
      " Training Loss----->   0.13341388786290098\n",
      "EPOCH-->21\n",
      " Training Loss----->   0.13115326751583015\n",
      "EPOCH-->22\n",
      " Training Loss----->   0.12899296044570036\n",
      "EPOCH-->23\n",
      " Training Loss----->   0.12692356033171098\n",
      "EPOCH-->24\n",
      " Training Loss----->   0.12493697134836382\n",
      "EPOCH-->25\n",
      " Training Loss----->   0.12302619317663399\n",
      "EPOCH-->26\n",
      " Training Loss----->   0.12118514388417906\n",
      "EPOCH-->27\n",
      " Training Loss----->   0.11940851379688208\n",
      "EPOCH-->28\n",
      " Training Loss----->   0.11769164473080425\n",
      "EPOCH-->29\n",
      " Training Loss----->   0.11603042998621195\n",
      "EPOCH-->30\n",
      " Training Loss----->   0.11442123135401139\n",
      "EPOCH-->31\n",
      " Training Loss----->   0.11286081007887067\n",
      "EPOCH-->32\n",
      " Training Loss----->   0.11134626928884356\n",
      "EPOCH-->33\n",
      " Training Loss----->   0.10987500586123522\n",
      "EPOCH-->34\n",
      " Training Loss----->   0.10844467006807353\n",
      "EPOCH-->35\n",
      " Training Loss----->   0.10705313164792654\n",
      "EPOCH-->36\n",
      " Training Loss----->   0.10569845119717798\n",
      "EPOCH-->37\n",
      " Training Loss----->   0.10437885597404338\n",
      "EPOCH-->38\n",
      " Training Loss----->   0.10309271937137865\n",
      "EPOCH-->39\n",
      " Training Loss----->   0.1018385434468293\n",
      "EPOCH-->40\n",
      " Training Loss----->   0.1006149440068507\n",
      "EPOCH-->41\n",
      " Training Loss----->   0.09942063782926103\n",
      "EPOCH-->42\n",
      " Training Loss----->   0.09825443168102117\n",
      "EPOCH-->43\n",
      " Training Loss----->   0.09711521284690597\n",
      "EPOCH-->44\n",
      " Training Loss----->   0.09600194093308993\n",
      "EPOCH-->45\n",
      " Training Loss----->   0.09491364074938893\n",
      "EPOCH-->46\n",
      " Training Loss----->   0.0938493961065879\n",
      "EPOCH-->47\n",
      " Training Loss----->   0.09280834439222996\n",
      "EPOCH-->48\n",
      " Training Loss----->   0.09178967181049616\n",
      "EPOCH-->49\n",
      " Training Loss----->   0.09079260919022018\n",
      "EPOCH-->50\n",
      " Training Loss----->   0.08981642828034747\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.train(X,y,2,50,metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.25712639, 0.74287361]]), array([1], dtype=int64))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fd63373fc8>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
